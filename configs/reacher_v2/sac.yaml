type: "SACAgent"
hyper_params:
  gamma: 0.99
  tau: 0.005
  buffer_size: 100000
  batch_size: 512
  initial_random_action: 20000
  multiple_update: 1  # multiple learning updates
  policy_update_freq: 2
  w_entropy: 0.001
  w_mean_reg: 0.001
  w_std_reg: 0.001
  w_pre_activation_reg: 0.0
  auto_entropy_tuning: True

learner_cfg:
  type: "SACLearner"
  backbone:
    actor:
    critic_vf:
    critic_qf:
  head:
    actor:
      type: "TanhGaussianDistParams"
      configs: 
        hidden_sizes: [256, 256]
        output_activation: "identity"
    critic_vf:
      type: "MLP"
      configs:
        hidden_sizes: [256, 256]
        output_size: 1
        output_activation: "identity"
    critic_qf:
      type: "MLP"
      configs:
        hidden_sizes: [256, 256]
        output_size: 1
        output_activation: "identity"
  optim_cfg:
    lr_actor: 0.0003
    lr_vf: 0.0003
    lr_qf1: 0.0003
    lr_qf2: 0.0003
    lr_entropy: 0.0003
    weight_decay: 0.0
