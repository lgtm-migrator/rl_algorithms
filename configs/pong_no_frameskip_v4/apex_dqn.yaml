type: "ApeX"
hyper_params:
  gamma: 0.99
  tau: 0.005
  buffer_size: 100000  # openai baselines: 10000
  batch_size: 512  # openai baselines: 32
  update_starts_from: 30000  # openai baselines: 10000
  multiple_update: 1  # multiple learning updates
  train_freq: 1  # in openai baselines, train_freq = 4
  gradient_clip: 10.0  # dueling: 10.0
  n_step: 5
  w_n_step: 1.0
  w_q_reg: 0.0
  per_alpha: 0.6  # openai baselines: 0.6
  per_beta: 0.4
  per_eps: 0.000001
  max_epsilon: 1.0
  min_epsilon: 0.1  # openai baselines: 0.01
  epsilon_decay: 0.0000005  # openai baselines: 1e-7 / 1e-1
  # Grad_cam
  grad_cam_layer_list:
    - "backbone.cnn.cnn_0.cnn"
    - "backbone.cnn.cnn_1.cnn"
    - "backbone.cnn.cnn_2.cnn"
  # ApeX
  num_workers: 2
  local_buffer_max_size: 1000
  worker_update_interval: 50
  logger_interval: 1000
  max_update_step: 100000
  is_worker_log: True
  is_worker_render: False

learner_cfg:
  type: "DQNLearner"
  loss_type:
    type: "DQNLoss"
  backbone:
    type: "CNN"
    configs:
      input_sizes: [4, 32, 64]
      output_sizes: [32, 64, 64]
      kernel_sizes: [8, 4, 3]
      strides: [4, 2, 1]
      paddings: [1, 0, 0]
  head:
    type: "DuelingMLP"
    configs: 
      hidden_sizes: [512]
      output_activation: "identity"
      # NoisyNet
      use_noisy_net: False
  optim_cfg:
    lr_dqn: 0.0003
    weight_decay: 0.0
    adam_eps: 0.00000001

worker_cfg:
  type: "DQNWorker"
  device: "cpu"

logger_cfg:
  type: "DQNLogger"

comm_cfg:
  learner_buffer_port: 6554
  learner_worker_port: 6555
  worker_buffer_port: 6556
  learner_logger_port: 6557
  send_batch_port: 6558
  priorities_port: 6559
